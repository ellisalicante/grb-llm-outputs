{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83971a35",
   "metadata": {},
   "source": [
    "# Gender representation bias analysis\n",
    "\n",
    "Annotate a given dataset for gender representation using API inference.\n",
    "\n",
    "To annotate data for validation, uncomment the lines terminating with `# Validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "from together import Together\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "# Generator LLM\n",
    "#gen_model = \"gpt-4o-mini\"\n",
    "#gen_model = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "#gen_model = \"google/gemma-2-27b-it\"\n",
    "#gen_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "#gen_model = \"Qwen/Qwen2.5-7B-Instruct-Turbo\"\n",
    "#gen_model = \"cjvt/GaMS-1B-Chat\"\n",
    "gen_model = \"utter-project/EuroLLM-1.7B-Instruct\"\n",
    "#gen_model = \"claude-3-7-sonnet-20250219\"  # Validation\n",
    "\n",
    "# Evaluator LLM\n",
    "#eval_model = \"gpt-4o-2024-08-06\"\n",
    "#eval_model = \"gpt-4o-2024-11-20\"\n",
    "eval_model = \"gpt-4.1-2025-04-14\"\n",
    "#eval_model = \"meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8\"\n",
    "#eval_model = \"deepseek-ai/DeepSeek-V3\"\n",
    "\n",
    "dataset_name = \"stories\"\n",
    "exp_name = \"exp1\"\n",
    "\n",
    "lang = \"cs\"\n",
    "#lang = \"sl\"\n",
    "\n",
    "#run = 0  # Validation\n",
    "\n",
    "prompt_pathname = Path(f\"../../data/dataset-analysis/prompt-{lang}.txt\") # prompt pattern\n",
    "examples_pathname = Path(f\"../../data/dataset-analysis/examples-{lang}.txt\") # few-shot examples\n",
    "input_folder_string = f\"../../results/{dataset_name}/{exp_name}/{gen_model}/{lang}\"\n",
    "input_folder = Path(input_folder_string) # dataset to be analyzed\n",
    "output_folder = Path(input_folder_string.replace(\"/results/\", \"/grb/\"))\n",
    "#output_folder = Path(os.path.join(input_folder_string.replace(\"/results/\", \"/grb/\"), f\"{eval_model}\", f\"{run}\"))  # Validation\n",
    "\n",
    "tokenizer_lang_dict = {\"cs\": \"czech\", \"sl\": \"slovene\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b74c51-cdb5-4738-92e0-35bfd87fbac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with prompt_pathname.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    prompt_template = f.read()\n",
    "with examples_pathname.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    examples = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6640b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(sentence):\n",
    "    return prompt_template.replace(\"<EXAMPLES>\", examples).replace(\"<SENTENCE>\", sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f725aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_analysis_response(response):\n",
    "    if response.strip() == \"0\":\n",
    "        return []\n",
    "    results = []\n",
    "    for line in response.strip().split(\"\\n\"):\n",
    "        if len(line.strip().split(\" - \")) == 2 and \" - \" in line:\n",
    "            word, gender = line.strip().split(\" - \")\n",
    "            if gender in {\"M\", \"F\"}:\n",
    "                results.append({\"word\": word.strip(), \"class\": gender})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aee23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(client, text):\n",
    "    sentences = sent_tokenize(text, language=tokenizer_lang_dict[lang])\n",
    "    grb_results = []\n",
    "\n",
    "    for sentence in tqdm(sentences):\n",
    "        prompt = format_prompt(sentence)\n",
    "        response = client.chat.completions.create(\n",
    "            model=eval_model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        result = response.choices[0].message.content\n",
    "        analysis = parse_analysis_response(result)\n",
    "        grb_results.append({\"sentence\": sentence, \"analysis\": analysis})\n",
    "    return grb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33b150-b9e4-412e-b0fe-b01af17dba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_model.startswith(\"gpt\"):\n",
    "    client = OpenAI()\n",
    "else:\n",
    "    client = Together()\n",
    "\n",
    "\n",
    "output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for file in tqdm(list(input_folder.glob(\"*.json\"))):\n",
    "    with file.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    assistant_msg = next((msg[\"content\"] for msg in data[\"conversation\"] if msg[\"role\"] == \"assistant\"), \"\")\n",
    "    grb_data = analyze_text(client, assistant_msg)\n",
    "    data[\"grb\"] = grb_data\n",
    "\n",
    "    with (output_folder / file.name).open(\"w\", encoding=\"utf-8\") as out:\n",
    "        json.dump(data, out, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c5bff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
