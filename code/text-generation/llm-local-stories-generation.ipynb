{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11d813b",
   "metadata": {},
   "source": [
    "# Generate stories using LLMs through local inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0987fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param\n",
    "results_base_path = \"../../results\"\n",
    "dataset_name = \"stories\"\n",
    "experiment_name = \"exp1\"\n",
    "\n",
    "# Generator LLM\n",
    "#gen_model = \"cjvt/GaMS-1B-Chat\"\n",
    "gen_model = \"utter-project/EuroLLM-1.7B-Instruct\"\n",
    "\n",
    "system_prompt = None\n",
    "\n",
    "dataset_base_path = \"data\"\n",
    "\n",
    "#lang = \"cs\"\n",
    "lang = \"sl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7422488",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=gen_model,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "def inference(pipeline, messages):\n",
    "    response = pipeline(messages, max_length=500)\n",
    "    return response[0][\"generated_text\"][-1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_conversation_round(conversation, new_prompt):\n",
    "    conversation.append({\"role\": \"user\", \"content\": new_prompt})\n",
    "    response = inference(pipeline, conversation)\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response})\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from local JSON\n",
    "with open(os.path.join(dataset_base_path, dataset_name, f\"{lang}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd16314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory structure\n",
    "os.makedirs(os.path.join(results_base_path, dataset_name, experiment_name, gen_model, lang), exist_ok=True)\n",
    "\n",
    "# Iterate through prompts\n",
    "for id, sample in enumerate(dataset):\n",
    "    prompt = sample[\"prompt\"]\n",
    "\n",
    "    # Initialize conversation history\n",
    "    if system_prompt:\n",
    "        conversation = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    else:\n",
    "        conversation = []\n",
    "\n",
    "    # Add the prompt to the conversation and get the response\n",
    "    conversation = add_conversation_round(conversation, prompt)\n",
    "\n",
    "    # Prepare result\n",
    "    result = {\n",
    "        \"id\": id,\n",
    "        \"conversation\": conversation\n",
    "    }\n",
    "\n",
    "    # Save to JSON\n",
    "    output_file = os.path.join(results_base_path, dataset_name, experiment_name, gen_model, lang, f\"{id:06d}.json\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # Print progress\n",
    "    print(\"id:\", id)\n",
    "    print(\"Prompt:\", prompt)\n",
    "    print(\"Response:\", conversation[-1][\"content\"])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87817b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
