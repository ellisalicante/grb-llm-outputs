{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fca17c11",
   "metadata": {},
   "source": [
    "# Generate stories using LLMs through API inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60e625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from together import Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0987fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Param\n",
    "results_base_path = \"../../results\"\n",
    "\n",
    "dataset_name = \"stories\"\n",
    "#dataset_name = \"stories_val\"  # Validation dataset\n",
    "\n",
    "experiment_name = \"exp1\"\n",
    "\n",
    "# Generator LLM\n",
    "gen_model = \"gpt-4o-mini\"\n",
    "#gen_model = \"meta-llama/Llama-4-Scout-17B-16E-Instruct\"\n",
    "#gen_model = \"google/gemma-2-27b-it\"\n",
    "#gen_model = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "#gen_model = \"Qwen/Qwen2.5-7B-Instruct-Turbo\"\n",
    "#gen_model = \"claude-3-7-sonnet-20250219\"  # Validation dataset\n",
    "\n",
    "system_prompt = None\n",
    "\n",
    "dataset_base_path = \"../../data\"\n",
    "\n",
    "#lang = \"cs\"\n",
    "lang = \"sl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7422488",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gen_model.startswith(\"gpt\"):\n",
    "    client = OpenAI()\n",
    "elif gen_model.startswith(\"claude\"):\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n",
    "        base_url=\"https://api.anthropic.com/v1/\",\n",
    "    )\n",
    "else:\n",
    "    client = Together()\n",
    "\n",
    "def inference(client, messages):\n",
    "    response = client.chat.completions.create(model=gen_model, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_conversation_round(conversation, new_prompt):\n",
    "    conversation.append({\"role\": \"user\", \"content\": new_prompt})\n",
    "    response = inference(client, conversation)\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": response})\n",
    "    return conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958c3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from local JSON\n",
    "with open(os.path.join(dataset_base_path, dataset_name, f\"{lang}.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd16314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory structure\n",
    "os.makedirs(os.path.join(results_base_path, dataset_name, experiment_name, gen_model, lang), exist_ok=True)\n",
    "\n",
    "# Iterate through prompts\n",
    "for id, sample in enumerate(dataset):\n",
    "    prompt = sample[\"prompt\"]\n",
    "\n",
    "    # Initialize conversation history\n",
    "    if system_prompt:\n",
    "        conversation = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "    else:\n",
    "        conversation = []\n",
    "\n",
    "    # Add the prompt to the conversation and get the response\n",
    "    conversation = add_conversation_round(conversation, prompt)\n",
    "\n",
    "    # Prepare result\n",
    "    result = {\n",
    "        \"id\": id,\n",
    "        \"conversation\": conversation\n",
    "    }\n",
    "\n",
    "    # Save to JSON\n",
    "    output_file = os.path.join(results_base_path, dataset_name, experiment_name, gen_model, lang, f\"{id:06d}.json\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "    # Print progress\n",
    "    print(\"id:\", id)\n",
    "    print(\"Prompt:\", prompt)\n",
    "    print(\"Response:\", conversation[-1][\"content\"])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87817b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
